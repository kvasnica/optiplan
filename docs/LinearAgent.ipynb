{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `LinearAgent` class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `LinearAgent` class represents dynamical systems driven by time-varying state-update and output equations of the form\n",
    "\\begin{align}\n",
    "x(k+1) & = A(k) x(k) + B(k) u(k) + f(k),\\\\\n",
    "y(k) & = C(k) x(k) + D(k) u(k) + g(k).\n",
    "\\end{align}\n",
    "\n",
    "Here, $x \\in \\mathbb{R}^{n_x}$ is the state vector, $u \\in \\mathbb{R}^{n_u}$ is the vector of control inputs, and $y \\in \\mathbb{R}^{n_y}$ represents the vector of system's outputs. These variables are subject to time-varying constraints of the form\n",
    "\\begin{align}\n",
    "& x_{\\text{min}}(k) \\le x(k) \\le x_{\\text{max}}(k),\\\\\n",
    "& u_{\\text{min}}(k) \\le u(k) \\le u_{\\text{max}}(k),\\\\\n",
    "& y_{\\text{min}}(k) \\le y(k) \\le y_{\\text{max}}(k).\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Objects of the class serve as placeholders for storing the dynamics (represented by matrices $A$, $B$, $f$, $C$, $D$, and $g$), constraints, as well as information about the control objectives. In particular, the optimal control inputs are computed by solving the following optimal control problem:\n",
    "\\begin{align}\n",
    "\\min \\ &\n",
    "(x(N) - x_{\\text{ref}}(N))^T Q_{\\text{x}}(N) (x(N) - x_{\\text{ref}}(N)) + \\cdots\\\\\n",
    "& \\qquad \\cdots + \\sum_{k=0}^{N-1} (x(k) - x_{\\text{ref}}(k))^T Q_{\\text{x}}(k) (x(k) - x_{\\text{ref}}(k)) + \\cdots\\\\\n",
    "& \\qquad \\cdots + \\sum_{k=0}^{N-1} (u(k) - u_{\\text{ref}}(k))^T Q_{\\text{u}}(k) (u(k) - u_{\\text{ref}}(k)) +\\cdots\\\\\n",
    "& \\qquad \\cdots + \\sum_{k=0}^{N-1} (y(k) - y_{\\text{ref}}(k))^T Q_{\\text{y}}(k) (y(k) - y_{\\text{ref}}(k))\\\\\n",
    "\\text{s.t.} \\\n",
    "& x(k+1) = A(k) x(k) + B(k) u(k) + f(k), \\ k = 0, \\ldots, N-1,\\\\\n",
    "& y(k) = C(k) x(k) + D(k) u(k) + g(k), \\ k = 0, \\ldots, N-1,\\\\\n",
    "& x_{\\text{min}}(k) \\le x(k) \\le x_{\\text{max}}(k), \\ k = 0, \\ldots, N,\\\\\n",
    "& u_{\\text{min}}(k) \\le u(k) \\le u_{\\text{max}}(k), \\ k = 0, \\ldots, N-1,\\\\\n",
    "& y_{\\text{min}}(k) \\le y(k) \\le y_{\\text{max}}(k), \\ k = 0, \\ldots, N-1.\n",
    "\\end{align}\n",
    "\n",
    "The objective function employs time-varying penalty matrices $Q_{\\text{x}} \\in \\mathbb{R}^{n_{x} \\times n_x}$, $Q_{\\text{u}} \\in \\mathbb{R}^{n_{u} \\times n_u}$, and $Q_{\\text{y}} \\in \\mathbb{R}^{n_{y} \\times n_y}$ which penalize the deviation of respective signals from their references."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instances of the `LinearAgent` class are generated by calling the constructor with following mandatory inputs:\n",
    "* `nx` - number of states\n",
    "* `nu` - number of control inputs\n",
    "* `ny` - number of outputs\n",
    "* `N` - prediction horizon"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "agent = optiplan.LinearAgent('nx', nx, 'nu', nu, 'ny', ny, 'PredictionHorizon', N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a sample agent. Its dynamics will represented by 4 states:\n",
    "* `x1`: speed in the x-axis\n",
    "* `x2`: position in the x-axis\n",
    "* `x3`: speed in the y-axis\n",
    "* `x4`: position in the y-axis\n",
    "\n",
    "two control inputs:\n",
    "* `u1`: accelleration in the x-axis\n",
    "* `u2`: accelleration in the y-axis\n",
    "\n",
    "and two outputs:\n",
    "* `y1`: position in the x-axis\n",
    "* `y2`: position in the y-axis\n",
    "\n",
    "The dynamics in both axis is decoupled and each is represented by a discrete-time double integrator. The agent's movements will be optimized by a model predictive scheme with prediction horizon `N`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agent = \n",
       "\n",
       "  LinearAgent with properties:\n",
       "\n",
       "       A: [4x4x10 optiplan.AgentSignal]\n",
       "       B: [4x2x10 optiplan.AgentSignal]\n",
       "       f: [4x1x10 optiplan.AgentSignal]\n",
       "       C: [2x4x10 optiplan.AgentSignal]\n",
       "       D: [2x2x10 optiplan.AgentSignal]\n",
       "       g: [2x1x10 optiplan.AgentSignal]\n",
       "      nx: 4\n",
       "      nu: 2\n",
       "      ny: 2\n",
       "       N: 10\n",
       "       X: [4x1x11 optiplan.AgentSignal]\n",
       "       U: [2x1x10 optiplan.AgentSignal]\n",
       "       Y: [2x1x10 optiplan.AgentSignal]\n",
       "    Size: [2x1x10 optiplan.AgentSignal]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx = 4; nu = 2; ny = 2; N = 10;\n",
    "agent = optiplan.LinearAgent('nx', nx, 'nu', nu, 'ny', ny, 'PredictionHorizon', N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent has following properties:\n",
    "* `A`, `B`, `f`: matrices of the state-update equation $x(k+1) = A(k)x(k) + B(k)u(k) + f(k)$\n",
    "* `C`, `D`, `g`: matrices of the output equation $y(k) = C(k)x(k) + D(k)u(k) + g(k)$\n",
    "* `Size`: size of the agent given as a vector of `width` (in the x-axis) and `height` (in the y-axis)\n",
    "* `X`: open-loop predictions of system's states, i.e., $X = [x_0, x_1, \\ldots, x_N]$\n",
    "* `U`: open-loop predictions of system's inputs, i.e., $U = [u_0, u_1, \\ldots, u_{N-1}]$\n",
    "* `Y`: open-loop predictions of system's outputs, i.e., $Y = [y_0, y_1, \\ldots, y_{N-1}]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, all these properties are *parameters* which means that they can be time-varying. This is indicated by the value being set to `'parameter'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ans =\n",
       "\n",
       "parameter"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.A.Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To tell the tool that the respective quantity is fixed throughout the prediction horizon, set its `Value` property to the desired value. Here, we will indicate that the dynamics is indeed constant. To save typing, we will load some demo data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ts = 0.25;  % sampling time\n",
    "demo = optiplan.LinearAgent.demo2Ddata(Ts);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agent.A.Value = demo.A;\n",
    "agent.B.Value = demo.B;\n",
    "agent.f.Value = demo.f;\n",
    "agent.C.Value = demo.C;\n",
    "agent.D.Value = demo.D;\n",
    "agent.g.Value = demo.g;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The `agent.X`, `agent.Y`, and `agent.U` signals are special since they allow you to specify additional properties, such as min/max bounds, reference values to be tracked, and matrices which penalize the deviation of the respective signals from their reference values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ans = \n",
       "\n",
       "  4x1x11 AgentSignal array with properties:\n",
       "\n",
       "          Max: 'parameter'\n",
       "      Penalty: 'parameter'\n",
       "    Reference: 'parameter'\n",
       "          Min: 'parameter'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output means that the agent's state vector will be subjecto to bounds $x_{\\text{min}} \\le x_k \\le x_{\\text{max}}$ for $k = 0, \\ldots, N$, and both the lower as well as the upper bound are parametric (i.e., they are time-varying, not known at the present time, but their values will be provided during the implementation).\n",
    "\n",
    "Additionally, the difference between the state vector and the value in the `agent.X.Reference` will be minimized at each prediction step by adding $(x_k - x_{\\text{ref}})^T Q (x_k - x_{\\text{ref}})$ to the objective function. Here, $x_k$ is the prediction of the state vector at the $k$-th step, $x_{\\text{ref}}$ is what's stored in `agent.X.Reference`, and `agent.X.Penalty` specifies the value of the penalty matrix $Q$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish, you can declare some of these properties to be constant. Let's use constant min/max bounds and the penalty matrix, but keep the reference parametric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ans = \n",
       "\n",
       "  4x1x11 AgentSignal array with properties:\n",
       "\n",
       "          Max: [4x1 double]\n",
       "      Penalty: [4x4 double]\n",
       "    Reference: 'parameter'\n",
       "          Min: [4x1 double]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.X.Min = demo.xmin;\n",
    "agent.X.Max = demo.xmax;\n",
    "agent.X.Penalty = zeros(agent.nx);\n",
    "agent.X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sidenote: the tool automatically checks for correct dimensions of the signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Value must be a 4x1 vector/matrix.\n"
     ]
    }
   ],
   "source": [
    "agent.X.Min = [1; 2; 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the agent for collision avoidance, you should set its size by setting `agent.Size.Value` to a $n_y \\times 1$ vector (if the size is fixed), or to `parameter` (if the size can be changed during the simulation). Note that the agent's outputs are implicitly assumed to be the agent's positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_width = 1;\n",
    "y_height = 1;\n",
    "agent.Size.Value = [x_width; y_height];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's easy to loose track about which properties are fixed and which are parametric. No need to wory, though. Call the agent's `listParameters()` method to get the info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agent.U.Max        [2 1 10]\n",
       "agent.U.Min        [2 1 10]\n",
       "agent.U.Penalty    [2 2 10]\n",
       "agent.U.Reference  [2 1 10]\n",
       "agent.X.Reference  [4 1 11]\n",
       "agent.Y.Max        [2 1 10]\n",
       "agent.Y.Min        [2 1 10]\n",
       "agent.Y.Penalty    [2 2 10]\n",
       "agent.Y.Reference  [2 1 10]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.listParameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can switch a property from parametric to fixed at any time. To declare it as parametric, set its value to `'parameter'`. Fixed properties are indicated by double values. Lets fix the penalty matrices for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agent.U.Penalty = demo.Qu;\n",
    "agent.Y.Penalty = demo.Qy;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Matlab",
   "language": "matlab",
   "name": "matlab_kernel"
  },
  "language_info": {
   "codemirror_mode": "Octave",
   "file_extension": ".m",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-matlab",
   "name": "octave"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
